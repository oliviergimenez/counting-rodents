---
title: "Estimating muskrats abundance"
author: "Olivier Gimenez"
date: "Dec 2024"
output: 
  html_document:
    toc: TRUE
    toc_depth: 2
    number_sections: true
    theme: united
    highlight: tango
    df_print: paged
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      cache = TRUE, 
                      message = FALSE, 
                      warning = FALSE, 
                      dpi = 600, 
                      fig.height=6, 
                      fig.width = 1.777777*6)
library(tidyverse)
theme_set(theme_light())
```

# Motivation

Here I illustrate the use of random effect site on abundance. I use removal data on muskrats in the Netherlands. 

First things first, load the packages we will need:
```{r}
library(tidyverse)
library(sf)
library(cbsodataR)
library(ubms)
library(nimble)
library(MCMCvis)
library(patchwork)
```

# Get data

Read in muskrat data:
```{r}
muskrats <- read_delim("data/occurrence-muskrats.txt")
head(muskrats)
```

Extract data for January, February and March:
```{r}
muskrats_3month <-  muskrats %>%
mutate(
  Start_Date = as.Date(sub("/.*", "", eventDate)),  # extract start date
  End_Date = as.Date(sub(".*/", "", eventDate))    # extract end date
) %>%
  rowwise() %>%  # apply operations row-wise
  # calculate the month and year with maximum overlap
  mutate(
    interval_dates = list(seq(Start_Date, End_Date, by = "day")),  # generate sequence of dates in the interval
    Overlapping_Month = {
      # find the month for each date
      month_names <- format(interval_dates, "%B")
      
      # determine the month with the maximum count
      max_month <- month_names %>%
        table() %>%
        which.max() %>%
        names()
      
      max_month
    },
    Overlapping_Year = {
      # find the year for each date
      year_values <- format(interval_dates, "%Y")
      
      # determine the year with the maximum count
      max_year <- year_values %>%
        table() %>%
        which.max() %>%
        names()
      
      max_year
    }
  ) %>%
  ungroup() %>%
  select(-interval_dates)
```

Make it an `sf` object:
```{r}
muskrats_sf <- muskrats_3month %>%
  filter(Overlapping_Month %in% c("January", "February", "March")) %>%
  group_by(year, Overlapping_Month, decimalLatitude, decimalLongitude) %>%
  summarise(n = sum(individualCount)) %>%
  mutate(month = Overlapping_Month) %>%
  st_as_sf(coords = c("decimalLongitude", "decimalLatitude"), 
                        crs = 4326, 
                        agr = "constant")
```

Map the data by year after 2010:
```{r}
muskrats_sf %>% 
  filter(year > 2010) %>%
  ggplot() +
  geom_sf(aes(color = log(n))) + 
  scale_color_viridis_c() +
  labs(color = "number of removed \nmuskrats (log)") +
  facet_wrap(~year) +
  theme_void()
```

Map the data by month for year 2010:
```{r}
muskrats_sf %>% 
  filter(year == 2010) %>%
  ggplot() +
  geom_sf(aes(color = log(n))) + 
  scale_color_viridis_c() +
  labs(color = "number of removed \nmuskrats (log)") +
  facet_wrap(~month) +
  theme_void()
```

Get background map of netherlands w/ municipalities:
```{r}
# https://cran.r-project.org/web/packages/cbsodataR/vignettes/maps.html
cbs_maps <- cbs_get_maps()
netherlands <- cbs_get_sf("gemeente", 2023)

netherlands <- netherlands %>% 
  st_transform(crs = st_crs(muskrats_sf))
```

```{r}
plot(netherlands)
```


Now let's count the number of muskrats removed in each municipality. 
First we do a spatial join to associate points (muskrats) with polygons (cities):
```{r}
points_with_polygons <- st_join(muskrats_sf, 
                                netherlands, 
                                join = st_within)
```


Second, summarize counts:
```{r}
netherlands_with_counts <- points_with_polygons %>%
  group_by(statcode, month, year) %>% 
  summarize(
    total_n = sum(n, na.rm = TRUE),  
    .groups = "drop"
  )
```


Create all permutations of month, year and municipalities:
```{r}
all_months_years <- expand.grid(
  month = unique(muskrats_sf$month), 
  year = unique(muskrats_sf$year),
  statcode = netherlands$statcode
)
```


Fill in missing combinations of statcode, month, and year:
```{r}
netherlands_with_counts <- all_months_years %>%
  left_join(netherlands_with_counts %>% 
              st_drop_geometry(), # temporarily drop geometry to avoid mismatches
            by = c("statcode", "month", "year")) %>%
  mutate(total_n = ifelse(is.na(total_n), 0, total_n)) %>%
  right_join(netherlands, by = "statcode") %>%  # join back to netherlands
  st_as_sf()
```

Map by month:
```{r}
netherlands_with_counts %>% 
  ggplot() + 
  geom_sf(aes(fill=log(total_n)), color="#FFFFFF99") +
  scale_fill_viridis_c(direction = -1, option = "A")+ 
  labs(fill = "number of removed \nmuskrats (log)") +
  facet_wrap(~month) +
  theme_void()
```

Map by year (sum over months):
```{r}
netherlands_with_counts %>% 
  group_by(year, statcode) %>%
  summarise(n = sum(total_n)) %>%
  ggplot() + 
  geom_sf(aes(fill=log(n)), color="#FFFFFF99") +
  scale_fill_viridis_c(direction = -1)+ 
  labs(fill = "number of removed \nmuskrats (log)") +
  facet_wrap(~year) +
  theme_void()
```

# Model fitting

## Poisson distribution with `ubms`

Get temperatures:
```{r}
temp <- readRDS("data/temperature_netherlands.rds")
```

Visualize the removal data:
```{r}
counts <- netherlands_with_counts %>%
  filter(year == 2014) %>%
  group_by(statcode) %>%
  mutate(removal_sum = sum(total_n)) %>%
  slice(1) %>%
  select(-month) %>%
  ggplot() + 
  geom_sf(aes(fill = log(removal_sum))) +
  scale_fill_viridis_c(direction = -1, option = "A")+ 
  labs(fill = "number of muskrats \nremoved (log)") +
  ggspatial::annotation_scale(location = "bl", 
                              width_hint = 0.5,
                              height = unit(0.1, "cm"),       # Adjust the height of the scale bar
                              text_cex = 0.5) +
  ggspatial::annotation_north_arrow(location = "br",
                                    which_north = "true",
                                    style = ggspatial::north_arrow_fancy_orienteering,
                                    height = unit(1, "cm"),       # Adjust height of the north arrow
                                    width = unit(.8, "cm"))
counts
```

Visualize temperature:
```{r}
av_temp <- apply(temp[,2:4], 1, mean, na.rm = TRUE)
temp$av_temp <- av_temp
tmp <- netherlands_with_counts %>%
  filter(year == 2014) %>%
  left_join(temp) %>%
  ggplot() + 
  geom_sf(aes(fill = av_temp)) +
  scale_fill_viridis_c(direction = -1)+ 
  labs(fill = "temperature (Â°C)") +
  ggspatial::annotation_scale(location = "bl", 
                              width_hint = 0.5,
                              height = unit(0.1, "cm"),       # Adjust the height of the scale bar
                              text_cex = 0.5) +
  ggspatial::annotation_north_arrow(location = "br",
                                    which_north = "true",
                                    style = ggspatial::north_arrow_fancy_orienteering,
                                    height = unit(1, "cm"),       # Adjust height of the north arrow
                                    width = unit(.8, "cm"))
tmp
```

Assemble plots:
```{r}
counts / tmp
ggsave(filename = "dat_muskrats.png", height = 10, width = 6)
```


Pick muskrats removal data for year 2014:
```{r}
muskrats_ubms <- netherlands_with_counts %>%
  as_tibble %>%
  select(-geometry, - statnaam) %>%
  mutate(site = dense_rank(statcode)) %>% # renumber cities
  pivot_wider(
    names_from = month,
    values_from = total_n) %>% 
  select(January, February, March, site, statcode, year) %>%
  filter(year == 2014)
muskrats_ubms
```

Join muskrat removal data with covariate:
```{r}
muskrats_ubms <- muskrats_ubms %>% 
  left_join(temp)
```

Remove cities for which I have no temperature data:
```{r}
mask <- !is.na(muskrats_ubms[,7])
muskrats_ubms <- muskrats_ubms[mask,]
```


Get removal data:
```{r}
y <- as.matrix(muskrats_ubms[,c(1,2,3)])
```

For those cities where we have only 0's, replace by NA's as this probably means there was no effort:
```{r}
mask <- apply(y, 1, sum)
y[mask == 0, ] <- NA
```

Format site and observation covariates:
```{r}
site.covs <- data.frame(site = as_factor(muskrats_ubms$site),
                        temp = apply(muskrats_ubms[,7:9], 1, mean))

time <- matrix(c('january','february','march'),
               nrow = nrow(y),
               ncol = ncol(y), 
               byrow = TRUE)
```

Put everything in appropriate format for `ubms`:
```{r}
umf <- unmarkedFrameMPois(y = y, 
                          siteCovs = site.covs,
                          obsCovs = list(time = time),
                          type = "removal")

head(umf)
```

Fit model:
```{r}
fit <- stan_multinomPois(~time ~scale(temp) + (1|site), # detection, abundance in that order
                         data = umf, 
                         chains = 2, 
                         iter = 10000,
                         warmup = 5000,
                         thin = 5,
                         prior_intercept_state = normal(0, 1.5),
                         prior_coef_state = normal(0, 1.5))
```

Inspect results:
```{r}
fit
```

Check convergence:
```{r}
traceplot(fit, pars = c("beta_state", "beta_det"))
```

Get posterior densities:
```{r}
plot_posteriors(fit)#, pars=c("beta_state[SistemaSilvopastoril]"))
```

Plot abundance with respect to temperature:
```{r}
plot_marginal(fit, submodel = "state")
```

Get estimated capture probabilities:
```{r, eval=FALSE}
plot_marginal(fit, submodel = "det")
```

Report removal data and estimated abundance:
```{r}
cbind(apply(y, 1, sum), predict(fit, submodel="state"))
```

## Poisson distribution with `NIMBLE`

Double check the data we have:
```{r}
muskrats_ubms
```

For those cities where we have only 0's, there was probably no effort, just ignore them:
```{r}
mask <- apply(muskrats_ubms[,1:3], 1, sum)
dat <- muskrats_ubms[mask != 0, ]
```

Get constants and data ready:
```{r}
K <- nrow(dat) # nsites
J <- ncol(dat[,1:3]) # nsurveys
temp <- apply(dat[,7:9], 1, mean)
constants <- list(K = K, J = J) 
data <- list(y = dat[,1:3],
             n = apply(dat[,1:3], 1, sum),
             temp = (temp - mean(temp))/sd(temp))
```

Code of a model with temperature on abundance plus a site random effect, and month on capture:
```{r}
# code
code <- nimbleCode({
  for (i in 1:K) { # loop over sites
    
    # prob of cells
    pi[i,1] <- p[i,1] # survey 1
    for(j in 2:J){ # loop over surveys > 1
      pi[i,j] <- prod(1 - p[i,1:(j-1)]) * p[i,j]
    }
    pcap[i] <- sum(pi[i,1:J])
    
    # capture prob
    for(j in 1:J){ # loop over surveys
      cloglog(p[i,j]) <- alpha[j]
      pic[i,j] <- pi[i,j] / pcap[i]
    }
    
    # likelihood: observation
    y[i,1:J] ~ dmulti(pic[i,1:J], n[i]) # multinomial for each site
    n[i] ~ dbin(pcap[i], N[i]) # for each site
    # likelihood: process
    N[i] ~ dpois(lambda[i]) # for each site
    log(lambda[i]) <- beta[1] + beta[2] * temp[i] + eps[i]
    eps[i] ~ dnorm(0, sd = sdeps)
  } # end of loop over sites
  
  sdeps ~ dunif(0, 10)
  for (j in 1:J){
    alpha[j] ~ dnorm(0, sd = 1.5)
  }
  for (k in 1:2){
    beta[k] ~ dnorm(0, sd = 1.5)
  }
})
```

Pick initial values:
```{r}
pic.init <- array(runif(K*J,0.05,0.15), c(K,J))
pic.init <- pic.init / apply(pic.init, 1, sum)
Nin <- apply(dat[,1:3], 1, sum) + 10
inits <- function(){list(alpha = rep(0.1, J), 
                         pic = pic.init, 
                         beta = rep(0,2), 
                         N = Nin)}
```

Set things up:
```{r}
# create Nimble model
Rmodel <- nimbleModel(code = code, 
                      constants = constants, 
                      data = data, 
                      inits = inits())
Rmcmc <- compileNimble(Rmodel, showCompilerOutput = F)
#ModSpec <- configureMCMC(Rmodel, onlyRW = TRUE) # RW sampling 
#ModSpec <- configureMCMC(Rmodel) # Nimble picks the samplers
ModSpec <- configureMCMC(Rmodel, onlySlice = TRUE) # slice sampling 
ModSpec$resetMonitors()
ModSpec$addMonitors(c("alpha","N","beta","sdeps"))
Cmcmc <- buildMCMC(ModSpec)
Cmodel <- compileNimble(Cmcmc, project = Rmodel, resetFunctions = TRUE)
```

Run model:
```{r}
ni <- 50000*4
nb <- 5000*4
nc <- 2
nt <- 15
samp <- runMCMC(Cmodel, 
                niter = ni, 
                nburnin = nb, 
                nchains = nc, 
                thin = nt, 
                inits = inits,  
                samplesAsCodaMCMC = TRUE)
```

Get a summary of the results:
```{r}
MCMCsummary(samp, params=c("alpha","beta","sdeps"))
```

Check convergence:
```{r}
MCMCtrace(samp, params = c("alpha","beta","sdeps"), pdf = FALSE)
```

Build map of estimated number of muskrats remaining after removal. First, compute the estimated number of muskrats:
```{r}
res <- rbind(samp$chain1, samp$chain2)
mask <- str_detect(colnames(res), "N")
N_mean <- apply(res[,mask], 2, mean)
N_sd <- apply(res[,mask], 2, sd)
N_estim <- tibble(N_mean = N_mean,
                  N_sd = N_sd,
                  N_cv = N_sd/N_mean*100)
N_estim$statcode <- dat$statcode
N_to_map <- netherlands_with_counts %>% 
  filter(year == 2014) %>%
  left_join(N_estim) %>%
  filter(!is.na(N_mean)) %>%
  mutate(N_mean = round(N_mean)) %>%
  group_by(statcode) %>%
  mutate(removed = sum(total_n)) %>%
  slice(1) %>%
  select(-month,-year,-total_n,-statnaam)
```

Build maps:
```{r}
plot_mean <- ggplot() + 
  geom_sf(data = netherlands, fill = NA) + 
  geom_sf(data = N_to_map, aes(fill = log(N_mean)), color = "#FFFFFF99") +
  scale_fill_viridis_c(direction = -1, option = "A") + 
  labs(fill = "# muskrats (log)") +
  theme(
    legend.title = element_text(hjust = 0.5, vjust = 1),
 #   legend.position = "top",
    plot.margin = margin(5, 5, 5, 5),
    legend.key.size = unit(0.5, "cm"),
    legend.spacing.x = unit(0.3, "cm")
  )  + 
  geom_sf(data = netherlands, fill = NA)+
#  coord_sf(datum = NA, expand = FALSE) +
  ggspatial::annotation_scale(location = "bl", 
                              width_hint = 0.5,
                              height = unit(0.1, "cm"),       # Adjust the height of the scale bar
                              text_cex = 0.5) +                 # Adjust the text size) 
  ggspatial::annotation_north_arrow(location = "br",
                                    which_north = "true",
                                    style = ggspatial::north_arrow_fancy_orienteering,
                                    height = unit(1, "cm"),       # Adjust height of the north arrow
                                    width = unit(0.8, "cm"))          # Adjust width of the north arrow)

plot_cv <- ggplot() + 
  geom_sf(data = netherlands, fill = NA) + 
  geom_sf(data = N_to_map, aes(fill = N_cv), color = "#FFFFFF99") +
  scale_fill_viridis_c(direction = -1) + 
  labs(fill = "CV (%)") +
  theme(
    legend.title = element_text(hjust = 0.5, vjust = 1),
  #      legend.position = "top",
    plot.margin = margin(5, 5, 5, 5),
    legend.key.size = unit(0.5, "cm"),
    legend.spacing.x = unit(0.3, "cm")
  )  + 
  geom_sf(data = netherlands, fill = NA)+
#  coord_sf(datum = NA, expand = FALSE) +
  ggspatial::annotation_scale(location = "bl", 
                              width_hint = 0.5,
                              height = unit(0.1, "cm"),       # Adjust the height of the scale bar
                              text_cex = 0.5) +
  ggspatial::annotation_north_arrow(location = "br",
                                    which_north = "true",
                                    style = ggspatial::north_arrow_fancy_orienteering,
                                    height = unit(1, "cm"),       # Adjust height of the north arrow
                                    width = unit(.8, "cm"))         # Adjust width of the north arrow)

# Combine the plots
plot_combined <- plot_mean / plot_cv

# Display the combined plot
print(plot_combined)

```


```{r}
ggsave(filename = "muskrats.png", plot = plot_combined, width = 10, height = 6)
```


## Varying-coefficient model with `NIMBLE`

Format data:
```{r}
muskrats_ubms <- netherlands_with_counts %>%
  as_tibble %>%
  select(-geometry, - statnaam) %>%
  mutate(site = dense_rank(statcode)) %>% # renumber cities
  pivot_wider(
    names_from = month,
    values_from = total_n) %>% 
  select(January, February, March, site, statcode, year)
muskrats_ubms
```

Join with temperature:
```{r}
temp_allyear <- readRDS("data/temperature_netherlands_allperiod.rds")
muskrats_ubms <- muskrats_ubms %>% 
  left_join(temp_allyear)
```

Make it an array:
```{r}
y <- base::array(NA, dim = c(342, 3, 28))
for (i in 1:342){
    for (k in 1987:2014){
      y[i,1:3,k-1986] <- muskrats_ubms %>% 
        filter(site == i, year == k) %>% 
        select(January, February, March) %>%
        as_vector()
    }
}
```

Idem for temperature:
```{r}
tt <- matrix(NA, nrow = 342, ncol = 28)
for (i in 1:342){
    for (k in 1987:2014){
      tt[i,k-1986] <- muskrats_ubms %>% 
        filter(site == i, year == k) %>% 
        select(mean_temperature) %>%
        as_vector()
    }
}
```

Remove cities for which I have no temperature data:
```{r}
mask <- !is.na(apply(tt, 1, sum))
tt <- tt[mask,]
y <- y[mask,,]
```

For those cities where we have only 0's, there was probably no effort, just ignore them:
```{r}
mask <- apply(apply(y, c(1,3), sum), 1, sum) == 0
tt <- tt[!mask,]
y <- y[!mask,,]
```

Get constants and data ready:
```{r}
K <- dim(y)[1] # nsites
J <- dim(y)[2] # nsurveys
L <- dim(y)[3] # nyears
temp <- tt
constants <- list(K = K, J = J, L = L) 
data <- list(y = y,
             n = apply(y, c(1,3), sum),
             temp = (temp - mean(temp))/sd(temp))
```

Code of a model with temperature on abundance varying over time, and month on capture:
```{r}
# code
code <- nimbleCode({
  for (i in 1:K) { # loop over sites
    # prob of cells
    pi[i,1] <- p[i,1] # survey 1
    for(j in 2:J){ # loop over surveys > 1
      pi[i,j] <- prod(1 - p[i,1:(j-1)]) * p[i,j]
    }
    pcap[i] <- sum(pi[i,1:J])
    
    # capture prob
    for(j in 1:J){ # loop over surveys
      cloglog(p[i,j]) <- alpha[j]
      pic[i,j] <- pi[i,j] / pcap[i]
    }
  }
  for (l in 1:L){ # loop over years
    for (i in 1:K){ # loop over sites
      # likelihood: observation
      y[i,1:J,l] ~ dmulti(pic[i,1:J], n[i,l]) # multinomial for each site/year
      n[i,l] ~ dbin(pcap[i], N[i,l]) # for each site/year
      # likelihood: process
      N[i,l] ~ dpois(lambda[i,l]) # for each site
      log(lambda[i,l]) <- intercept + slope[l] * temp[i,l] #+ eps[i]
    } # end of loop over sites
  }  # end of loop over years

  intercept ~ dnorm(0, sd = 1.5)
#  for (i in 1:L){
#    eps[i] ~ dnorm(0, sd = sdeps)
#  }  
#  sdeps ~ dunif(0, 10)
  for (j in 1:J){
    alpha[j] ~ dnorm(0, sd = 1.5)
  }
  for (j in 1:2){
    beta[j] ~ dnorm(0, sd = 1.5)
  }
  for (l in 1:L){
    slope[l] <- beta[1] + beta[2] * (l-14.5)/8.23
  }
})
```

Pick initial values:
```{r}
pic.init <- array(runif(K*J,0.05,0.15), c(K,J))
pic.init <- pic.init / apply(pic.init, 1, sum)
Nin <- apply(y, c(1,3), sum) + 10
inits <- function(){list(alpha = rep(0.1, J), 
                         pic = pic.init, 
                         beta = rep(0,2), 
                         N = Nin)}
```

Set things up:
```{r}
# create Nimble model
Rmodel <- nimbleModel(code = code, 
                      constants = constants, 
                      data = data, 
                      inits = inits())
Rmcmc <- compileNimble(Rmodel, showCompilerOutput = F)
#ModSpec <- configureMCMC(Rmodel, onlyRW = TRUE) # RW sampling 
ModSpec <- configureMCMC(Rmodel) # Nimble picks the samplers
#ModSpec <- configureMCMC(Rmodel, onlySlice = TRUE) # slice sampling 
ModSpec$resetMonitors()
#ModSpec$addMonitors(c("alpha","beta","sdeps","intercept","slope"))
ModSpec$addMonitors(c("alpha","beta","intercept","slope"))
Cmcmc <- buildMCMC(ModSpec)
Cmodel <- compileNimble(Cmcmc, project = Rmodel, resetFunctions = TRUE)
```

Run model:
```{r}
ni <- 5000
nb <- 500
nc <- 2
nt <- 1
samp <- runMCMC(Cmodel, 
                niter = ni, 
                nburnin = nb, 
                nchains = nc, 
                thin = nt, 
                inits = inits,  
                samplesAsCodaMCMC = TRUE)
```

Get a summary of the results:
```{r}
MCMCsummary(samp, params=c("beta"))
```

Check convergence:
```{r}
MCMCtrace(samp, 
          params = c("beta"), 
          pdf = FALSE)
```




<!-- ## Overdispersion and negative binomial distribution with `NIMBLE` -->

<!-- We fit the same model as in the previous section, and use a negative binomial distribution instead of a Poisson distribution:  -->
<!-- ```{r} -->
<!-- code <- nimbleCode({ -->
<!--   for (i in 1:K) { # loop over sites -->

<!--     # prob of cells -->
<!--     pi[i,1] <- p[i,1] # survey 1 -->
<!--     for(j in 2:J){ # loop over surveys > 1 -->
<!--       pi[i,j] <- prod(1 - p[i,1:(j-1)]) * p[i,j] -->
<!--     } -->
<!--     pcap[i] <- sum(pi[i,1:J]) -->

<!--     # capture prob fn of effort -->
<!--     for(j in 1:J){ # loop over surveys -->
<!--       cloglog(p[i,j]) <- alpha[j]  -->
<!--       pic[i,j] <- pi[i,j] / pcap[i] -->
<!--     } -->

<!--     # likelihood: observation -->
<!--     y[i,1:J] ~ dmulti(pic[i,1:J], n[i]) # multinomial for each site -->
<!--     n[i] ~ dbin(pcap[i], N[i]) # for each site -->
<!--     # likelihood: process -->
<!--     N[i] ~ dnegbin(pp[i], r) -->
<!--     pp[i] <- r / (r + lambda[i])  -->
<!--     log(lambda[i]) <- beta[1] + beta[2] * temp[i] + eps[i] -->
<!--     eps[i] ~ dnorm(0, sd = sdeps) -->
<!--   } # end of loop over sites -->

<!--   sdeps ~ dunif(0,10) -->
<!--   r ~ dunif(0.01,50) -->

<!--   for (j in 1:J){ -->
<!--     alpha[j] ~ dnorm(0, sd = 1.5) -->
<!--   } -->
<!--   for (k in 1:2){ -->
<!--     beta[k] ~ dnorm(0, sd = 1.5) -->
<!--   } -->
<!-- }) -->

<!-- pic.init <- array(runif(K*J,0.05,0.15), c(K,J)) -->
<!-- pic.init <- pic.init / apply(pic.init, 1, sum) -->
<!-- Nin <- apply(dat[,1:3], 1, sum) + 10 -->
<!-- inits <- function(){list(alpha = rep(0.1, J),  -->
<!--                          pic = pic.init,  -->
<!--                          beta = rep(0,2),  -->
<!--                          N = Nin)} -->

<!-- Rmodel <- nimbleModel(code = code,  -->
<!--                       constants = constants,  -->
<!--                       data = data,  -->
<!--                       inits = inits()) -->
<!-- Rmcmc <- compileNimble(Rmodel, showCompilerOutput = F) -->
<!-- #ModSpec <- configureMCMC(Rmodel, onlyRW = TRUE) # RW sampling  -->
<!-- #ModSpec <- configureMCMC(Rmodel) # Nimble picks the samplers -->
<!-- ModSpec <- configureMCMC(Rmodel, onlySlice = TRUE) # slice sampling  -->
<!-- ModSpec$resetMonitors() -->
<!-- ModSpec$addMonitors(c("alpha","N","beta","r","sdeps")) -->
<!-- Cmcmc <- buildMCMC(ModSpec) -->
<!-- Cmodel <- compileNimble(Cmcmc, project = Rmodel, resetFunctions = TRUE) -->

<!-- ni <- 50000*4 -->
<!-- nb <- 5000*4 -->
<!-- nc <- 2 -->
<!-- nt <- 15 -->

<!-- samp <- runMCMC(Cmodel,  -->
<!--                 niter = ni,  -->
<!--                 nburnin = nb,  -->
<!--                 nchains = nc,  -->
<!--                 thin = nt,  -->
<!--                 inits = inits,   -->
<!--                 samplesAsCodaMCMC = TRUE) -->
<!-- ``` -->


<!-- ```{r} -->
<!-- MCMCsummary(samp, params=c("alpha","beta", "r", "sdeps")) -->
<!-- ``` -->


<!-- ```{r} -->
<!-- MCMCtrace(samp, params = c("alpha","beta", "r", "sdeps"), pdf = FALSE) -->
<!-- ``` -->

# Session info

```{r}
sessionInfo()
```

